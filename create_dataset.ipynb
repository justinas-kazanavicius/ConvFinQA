{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "\n",
    "langfuse = Langfuse(\n",
    "    secret_key=\"sk-lf-a65b23f9-0ffb-4063-8c09-5e1c265e9c4a\",\n",
    "    public_key=\"pk-lf-c5d11bfe-392e-4ae1-ad90-aa4a8639965c\",\n",
    "    host=\"https://cloud.langfuse.com\"\n",
    "  # host=\"https://us.cloud.langfuse.com\", # ðŸ‡ºðŸ‡¸ US region\n",
    ")\n",
    "\n",
    "\n",
    "# langfuse = Langfuse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.documents import Document\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def create_convfinqa_langfuse_dataset(filepath, name, description, limit: int = None):\n",
    "    langfuse.create_dataset(name=name, description=description)\n",
    "    with open(filepath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    docs = []\n",
    "    \n",
    "    QA_FIELDS = [\"qa\", *[f\"qa_{i}\" for i in range(10)]]\n",
    "    SKIPPED_METADATA_FIELDS = ['annotation', *QA_FIELDS]\n",
    "    if limit:\n",
    "        data = data[:limit]\n",
    "\n",
    "    for entry in tqdm(data):\n",
    "        # Combine pre_text, post_text, and table content into a single text block\n",
    "\n",
    "        # Loop through every available QA field in the entry\n",
    "        for qa_field in set(QA_FIELDS).intersection(entry.keys()):\n",
    "            # Upload to Langfuse\n",
    "            langfuse.create_dataset_item(\n",
    "                dataset_name=name,\n",
    "                # any python object or value\n",
    "                input=entry[qa_field][\"question\"],\n",
    "                # any python object or value, optional\n",
    "                expected_output=entry[qa_field][\"answer\"],\n",
    "                metadata={\n",
    "                    \"document\": {field: entry[field] for field in entry.keys() if field not in SKIPPED_METADATA_FIELDS},\n",
    "                }\n",
    "            )\n",
    "  \n",
    "        # # Process the table to include in the text block\n",
    "        table_text = []\n",
    "        for row in entry['table']:\n",
    "            # Join each cell in the row with a tab for clarity\n",
    "            table_text.append(\"\\t\".join(row))\n",
    "    \n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['qa', 'qa_0', 'qa_1', 'qa_2', 'qa_3', 'qa_4', 'qa_5', 'qa_6', 'qa_7', 'qa_8', 'qa_9']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'ConvFinQA/data/train.json'\n",
    "docs = create_convfinqa_langfuse_dataset(DATA_PATH, \"convfinqa-train\", \"Dataset created from ConvFinQA train data\", limit=1000)\n",
    "print(docs)\n",
    "# vector_store.add_documents(docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
